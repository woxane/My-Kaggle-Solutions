{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a267a9ed-abd2-4a9d-aa7a-c2854b936d12",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "503062f8-2014-4409-b3f0-31453b82bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "78b4e23c-18d4-4f24-b7ef-220b09742105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df_preprocessed = pd.get_dummies(df, drop_first=True, dtype=int).astype(float)\n",
    "X = df_preprocessed.drop(['accident_risk', 'id'], axis=1)\n",
    "y = df_preprocessed['accident_risk']\n",
    "\n",
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d61550-5d09-478d-b7d5-832da6700535",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fc38f149-e168-4d8a-b05f-16c66a2b1412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_generator(trained_model, test_df):\n",
    "    preprocessed_df = pd.get_dummies(test_df, drop_first=True, dtype=int).astype(float).drop('id', axis=1)\n",
    "\n",
    "    return pd.concat([test_df['id'], pd.Series(clf.predict(test_df_p))], axis=1).rename({0: 'accident_risk'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164c3e66-b324-42ff-95cc-24ebda8c1efd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Evaluation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89c9401f-a55d-4be4-a3e9-7fd2dd119f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "kf = KFold(5, shuffle=True)\n",
    "\n",
    "def evaluate_model(model_object, X, verbose=True, **kwargs):\n",
    "    rmses = []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        train_data = X.iloc[train_index]\n",
    "        test_data = X.iloc[test_index]\n",
    "\n",
    "        train_output = y.iloc[train_index]\n",
    "        test_output = y.iloc[test_index]\n",
    "\n",
    "        model = model_object(**kwargs)\n",
    "        model.fit(train_data, train_output)\n",
    "\n",
    "        y_pred = model.predict(test_data)\n",
    "\n",
    "        rmse = root_mean_squared_error(y_pred, test_output)\n",
    "        if verbose:\n",
    "            print(f\"fold: {i}, rmse: {rmse:.6f}\")\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return np.mean(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c57c03-a13a-46c1-a771-e90ee1ccd360",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e7d72d-1e69-4204-9c01-f15788dc3b99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a422e287-e4af-4a54-9941-0168c56cbb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1a8072d-e2f2-45d4-a93a-0a0d239a560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linear_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3316830-e620-4dbb-a390-8cf88e44c008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07330965157891249"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e007abb-81c9-458b-ad4a-07c82508f122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, rmse: 0.07342207604557457\n",
      "fold: 1, rmse: 0.07333548214978462\n",
      "fold: 2, rmse: 0.07347474666973686\n",
      "fold: 3, rmse: 0.07360227905727774\n",
      "fold: 4, rmse: 0.07364548672122433\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(5, shuffle=True)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    linear_regression.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "    y_pred = linear_regression.predict(X.iloc[test_index])\n",
    "    rmse = root_mean_squared_error(y.iloc[test_index], y_pred)\n",
    "    print(f\"fold: {i}, rmse: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72869407-13c7-4f7e-a2e0-9be64aeb3732",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58480f33-8b8a-4648-99fc-3cfdc04e11ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f051c96c-06d3-4f13-ad15-952dadbf127a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 2, min_samples_split: 2, rmse: 0.118667\n",
      "max_depth: 2, min_samples_split: 22, rmse: 0.118668\n",
      "max_depth: 2, min_samples_split: 42, rmse: 0.118667\n",
      "max_depth: 2, min_samples_split: 62, rmse: 0.118668\n",
      "max_depth: 2, min_samples_split: 82, rmse: 0.118668\n",
      "max_depth: 2, min_samples_split: 102, rmse: 0.118667\n",
      "max_depth: 2, min_samples_split: 122, rmse: 0.118668\n",
      "max_depth: 2, min_samples_split: 142, rmse: 0.118668\n",
      "max_depth: 2, min_samples_split: 162, rmse: 0.118668\n",
      "max_depth: 2, min_samples_split: 182, rmse: 0.118667\n",
      "max_depth: 2, min_samples_split: 202, rmse: 0.118667\n",
      "max_depth: 2, min_samples_split: 222, rmse: 0.118668\n",
      "max_depth: 2, min_samples_split: 242, rmse: 0.118667\n",
      "max_depth: 2, min_samples_split: 262, rmse: 0.118668\n",
      "max_depth: 2, min_samples_split: 282, rmse: 0.118668\n",
      "max_depth: 2, min_samples_split: 302, rmse: 0.118667\n",
      "max_depth: 2, min_samples_split: 322, rmse: 0.118668\n",
      "max_depth: 2, min_samples_split: 342, rmse: 0.118668\n",
      "max_depth: 2, min_samples_split: 362, rmse: 0.118668\n",
      "max_depth: 2, min_samples_split: 382, rmse: 0.118668\n",
      "max_depth: 2, min_samples_split: 402, rmse: 0.118668\n",
      "max_depth: 2, min_samples_split: 422, rmse: 0.118667\n",
      "max_depth: 2, min_samples_split: 442, rmse: 0.118667\n",
      "max_depth: 2, min_samples_split: 462, rmse: 0.118667\n",
      "max_depth: 2, min_samples_split: 482, rmse: 0.118668\n",
      "max_depth: 7, min_samples_split: 2, rmse: 0.057934\n",
      "max_depth: 7, min_samples_split: 22, rmse: 0.057953\n",
      "max_depth: 7, min_samples_split: 42, rmse: 0.057948\n",
      "max_depth: 7, min_samples_split: 62, rmse: 0.057967\n",
      "max_depth: 7, min_samples_split: 82, rmse: 0.057947\n",
      "max_depth: 7, min_samples_split: 102, rmse: 0.057948\n",
      "max_depth: 7, min_samples_split: 122, rmse: 0.057971\n",
      "max_depth: 7, min_samples_split: 142, rmse: 0.057954\n",
      "max_depth: 7, min_samples_split: 162, rmse: 0.057956\n",
      "max_depth: 7, min_samples_split: 182, rmse: 0.057941\n",
      "max_depth: 7, min_samples_split: 202, rmse: 0.057950\n",
      "max_depth: 7, min_samples_split: 222, rmse: 0.057940\n",
      "max_depth: 7, min_samples_split: 242, rmse: 0.057948\n",
      "max_depth: 7, min_samples_split: 262, rmse: 0.057938\n",
      "max_depth: 7, min_samples_split: 282, rmse: 0.057953\n",
      "max_depth: 7, min_samples_split: 302, rmse: 0.057958\n",
      "max_depth: 7, min_samples_split: 322, rmse: 0.057950\n",
      "max_depth: 7, min_samples_split: 342, rmse: 0.057954\n",
      "max_depth: 7, min_samples_split: 362, rmse: 0.057949\n",
      "max_depth: 7, min_samples_split: 382, rmse: 0.057954\n",
      "max_depth: 7, min_samples_split: 402, rmse: 0.057959\n",
      "max_depth: 7, min_samples_split: 422, rmse: 0.057943\n",
      "max_depth: 7, min_samples_split: 442, rmse: 0.057943\n",
      "max_depth: 7, min_samples_split: 462, rmse: 0.057942\n",
      "max_depth: 7, min_samples_split: 482, rmse: 0.057946\n",
      "max_depth: 12, min_samples_split: 2, rmse: 0.056975\n",
      "max_depth: 12, min_samples_split: 22, rmse: 0.056723\n",
      "max_depth: 12, min_samples_split: 42, rmse: 0.056686\n",
      "max_depth: 12, min_samples_split: 62, rmse: 0.056632\n",
      "max_depth: 12, min_samples_split: 82, rmse: 0.056582\n",
      "max_depth: 12, min_samples_split: 102, rmse: 0.056588\n",
      "max_depth: 12, min_samples_split: 122, rmse: 0.056550\n",
      "max_depth: 12, min_samples_split: 142, rmse: 0.056523\n",
      "max_depth: 12, min_samples_split: 162, rmse: 0.056524\n",
      "max_depth: 12, min_samples_split: 182, rmse: 0.056489\n",
      "max_depth: 12, min_samples_split: 202, rmse: 0.056441\n",
      "max_depth: 12, min_samples_split: 222, rmse: 0.056459\n",
      "max_depth: 12, min_samples_split: 242, rmse: 0.056453\n",
      "max_depth: 12, min_samples_split: 262, rmse: 0.056464\n",
      "max_depth: 12, min_samples_split: 282, rmse: 0.056459\n",
      "max_depth: 12, min_samples_split: 302, rmse: 0.056457\n",
      "max_depth: 12, min_samples_split: 322, rmse: 0.056424\n",
      "max_depth: 12, min_samples_split: 342, rmse: 0.056456\n",
      "max_depth: 12, min_samples_split: 362, rmse: 0.056395\n",
      "max_depth: 12, min_samples_split: 382, rmse: 0.056445\n",
      "max_depth: 12, min_samples_split: 402, rmse: 0.056414\n",
      "max_depth: 12, min_samples_split: 422, rmse: 0.056382\n",
      "max_depth: 12, min_samples_split: 442, rmse: 0.056430\n",
      "max_depth: 12, min_samples_split: 462, rmse: 0.056396\n",
      "max_depth: 12, min_samples_split: 482, rmse: 0.056408\n",
      "max_depth: 17, min_samples_split: 2, rmse: 0.067241\n",
      "max_depth: 17, min_samples_split: 22, rmse: 0.060529\n",
      "max_depth: 17, min_samples_split: 42, rmse: 0.058783\n",
      "max_depth: 17, min_samples_split: 62, rmse: 0.058098\n",
      "max_depth: 17, min_samples_split: 82, rmse: 0.057595\n",
      "max_depth: 17, min_samples_split: 102, rmse: 0.057302\n",
      "max_depth: 17, min_samples_split: 122, rmse: 0.057149\n",
      "max_depth: 17, min_samples_split: 142, rmse: 0.057002\n",
      "max_depth: 17, min_samples_split: 162, rmse: 0.056928\n",
      "max_depth: 17, min_samples_split: 182, rmse: 0.056825\n",
      "max_depth: 17, min_samples_split: 202, rmse: 0.056730\n",
      "max_depth: 17, min_samples_split: 222, rmse: 0.056699\n",
      "max_depth: 17, min_samples_split: 242, rmse: 0.056630\n",
      "max_depth: 17, min_samples_split: 262, rmse: 0.056621\n",
      "max_depth: 17, min_samples_split: 282, rmse: 0.056595\n",
      "max_depth: 17, min_samples_split: 302, rmse: 0.056565\n",
      "max_depth: 17, min_samples_split: 322, rmse: 0.056530\n",
      "max_depth: 17, min_samples_split: 342, rmse: 0.056506\n",
      "max_depth: 17, min_samples_split: 362, rmse: 0.056492\n",
      "max_depth: 17, min_samples_split: 382, rmse: 0.056470\n",
      "max_depth: 17, min_samples_split: 402, rmse: 0.056472\n",
      "max_depth: 17, min_samples_split: 422, rmse: 0.056442\n",
      "max_depth: 17, min_samples_split: 442, rmse: 0.056416\n",
      "max_depth: 17, min_samples_split: 462, rmse: 0.056462\n",
      "max_depth: 17, min_samples_split: 482, rmse: 0.056430\n",
      "max_depth: 22, min_samples_split: 2, rmse: 0.081784\n",
      "max_depth: 22, min_samples_split: 22, rmse: 0.061637\n",
      "max_depth: 22, min_samples_split: 42, rmse: 0.059058\n",
      "max_depth: 22, min_samples_split: 62, rmse: 0.058139\n",
      "max_depth: 22, min_samples_split: 82, rmse: 0.057690\n",
      "max_depth: 22, min_samples_split: 102, rmse: 0.057369\n",
      "max_depth: 22, min_samples_split: 122, rmse: 0.057158\n",
      "max_depth: 22, min_samples_split: 142, rmse: 0.057001\n",
      "max_depth: 22, min_samples_split: 162, rmse: 0.056866\n",
      "max_depth: 22, min_samples_split: 182, rmse: 0.056813\n",
      "max_depth: 22, min_samples_split: 202, rmse: 0.056747\n",
      "max_depth: 22, min_samples_split: 222, rmse: 0.056673\n",
      "max_depth: 22, min_samples_split: 242, rmse: 0.056641\n",
      "max_depth: 22, min_samples_split: 262, rmse: 0.056628\n",
      "max_depth: 22, min_samples_split: 282, rmse: 0.056537\n",
      "max_depth: 22, min_samples_split: 302, rmse: 0.056527\n",
      "max_depth: 22, min_samples_split: 322, rmse: 0.056531\n",
      "max_depth: 22, min_samples_split: 342, rmse: 0.056501\n",
      "max_depth: 22, min_samples_split: 362, rmse: 0.056500\n",
      "max_depth: 22, min_samples_split: 382, rmse: 0.056441\n",
      "max_depth: 22, min_samples_split: 402, rmse: 0.056462\n",
      "max_depth: 22, min_samples_split: 422, rmse: 0.056459\n",
      "max_depth: 22, min_samples_split: 442, rmse: 0.056460\n",
      "max_depth: 22, min_samples_split: 462, rmse: 0.056438\n",
      "max_depth: 22, min_samples_split: 482, rmse: 0.056445\n",
      "max_depth: 27, min_samples_split: 2, rmse: 0.082990\n",
      "max_depth: 27, min_samples_split: 22, rmse: 0.061675\n",
      "max_depth: 27, min_samples_split: 42, rmse: 0.059071\n",
      "max_depth: 27, min_samples_split: 62, rmse: 0.058137\n",
      "max_depth: 27, min_samples_split: 82, rmse: 0.057648\n",
      "max_depth: 27, min_samples_split: 102, rmse: 0.057325\n",
      "max_depth: 27, min_samples_split: 122, rmse: 0.057148\n",
      "max_depth: 27, min_samples_split: 142, rmse: 0.056968\n",
      "max_depth: 27, min_samples_split: 162, rmse: 0.056892\n",
      "max_depth: 27, min_samples_split: 182, rmse: 0.056805\n",
      "max_depth: 27, min_samples_split: 202, rmse: 0.056719\n",
      "max_depth: 27, min_samples_split: 222, rmse: 0.056700\n",
      "max_depth: 27, min_samples_split: 242, rmse: 0.056650\n",
      "max_depth: 27, min_samples_split: 262, rmse: 0.056578\n",
      "max_depth: 27, min_samples_split: 282, rmse: 0.056599\n",
      "max_depth: 27, min_samples_split: 302, rmse: 0.056534\n",
      "max_depth: 27, min_samples_split: 322, rmse: 0.056529\n",
      "max_depth: 27, min_samples_split: 342, rmse: 0.056504\n",
      "max_depth: 27, min_samples_split: 362, rmse: 0.056495\n",
      "max_depth: 27, min_samples_split: 382, rmse: 0.056461\n",
      "max_depth: 27, min_samples_split: 402, rmse: 0.056485\n",
      "max_depth: 27, min_samples_split: 422, rmse: 0.056445\n",
      "max_depth: 27, min_samples_split: 442, rmse: 0.056424\n",
      "max_depth: 27, min_samples_split: 462, rmse: 0.056431\n",
      "max_depth: 27, min_samples_split: 482, rmse: 0.056404\n",
      "max_depth: 32, min_samples_split: 2, rmse: 0.082931\n",
      "max_depth: 32, min_samples_split: 22, rmse: 0.061578\n",
      "max_depth: 32, min_samples_split: 42, rmse: 0.059155\n",
      "max_depth: 32, min_samples_split: 62, rmse: 0.058136\n",
      "max_depth: 32, min_samples_split: 82, rmse: 0.057668\n",
      "max_depth: 32, min_samples_split: 102, rmse: 0.057350\n",
      "max_depth: 32, min_samples_split: 122, rmse: 0.057144\n",
      "max_depth: 32, min_samples_split: 142, rmse: 0.056989\n",
      "max_depth: 32, min_samples_split: 162, rmse: 0.056887\n",
      "max_depth: 32, min_samples_split: 182, rmse: 0.056795\n",
      "max_depth: 32, min_samples_split: 202, rmse: 0.056751\n",
      "max_depth: 32, min_samples_split: 222, rmse: 0.056698\n",
      "max_depth: 32, min_samples_split: 242, rmse: 0.056655\n",
      "max_depth: 32, min_samples_split: 262, rmse: 0.056650\n",
      "max_depth: 32, min_samples_split: 282, rmse: 0.056549\n",
      "max_depth: 32, min_samples_split: 302, rmse: 0.056551\n",
      "max_depth: 32, min_samples_split: 322, rmse: 0.056512\n",
      "max_depth: 32, min_samples_split: 342, rmse: 0.056492\n",
      "max_depth: 32, min_samples_split: 362, rmse: 0.056489\n",
      "max_depth: 32, min_samples_split: 382, rmse: 0.056467\n",
      "max_depth: 32, min_samples_split: 402, rmse: 0.056462\n",
      "max_depth: 32, min_samples_split: 422, rmse: 0.056473\n",
      "max_depth: 32, min_samples_split: 442, rmse: 0.056419\n",
      "max_depth: 32, min_samples_split: 462, rmse: 0.056428\n",
      "max_depth: 32, min_samples_split: 482, rmse: 0.056450\n",
      "max_depth: 37, min_samples_split: 2, rmse: 0.083020\n",
      "max_depth: 37, min_samples_split: 22, rmse: 0.061623\n",
      "max_depth: 37, min_samples_split: 42, rmse: 0.059043\n",
      "max_depth: 37, min_samples_split: 62, rmse: 0.058103\n",
      "max_depth: 37, min_samples_split: 82, rmse: 0.057634\n",
      "max_depth: 37, min_samples_split: 102, rmse: 0.057362\n",
      "max_depth: 37, min_samples_split: 122, rmse: 0.057161\n",
      "max_depth: 37, min_samples_split: 142, rmse: 0.057008\n",
      "max_depth: 37, min_samples_split: 162, rmse: 0.056846\n",
      "max_depth: 37, min_samples_split: 182, rmse: 0.056786\n",
      "max_depth: 37, min_samples_split: 202, rmse: 0.056765\n",
      "max_depth: 37, min_samples_split: 222, rmse: 0.056707\n",
      "max_depth: 37, min_samples_split: 242, rmse: 0.056656\n",
      "max_depth: 37, min_samples_split: 262, rmse: 0.056612\n",
      "max_depth: 37, min_samples_split: 282, rmse: 0.056569\n",
      "max_depth: 37, min_samples_split: 302, rmse: 0.056532\n",
      "max_depth: 37, min_samples_split: 322, rmse: 0.056542\n",
      "max_depth: 37, min_samples_split: 342, rmse: 0.056504\n",
      "max_depth: 37, min_samples_split: 362, rmse: 0.056499\n",
      "max_depth: 37, min_samples_split: 382, rmse: 0.056463\n",
      "max_depth: 37, min_samples_split: 402, rmse: 0.056469\n",
      "max_depth: 37, min_samples_split: 422, rmse: 0.056477\n",
      "max_depth: 37, min_samples_split: 442, rmse: 0.056442\n",
      "max_depth: 37, min_samples_split: 462, rmse: 0.056431\n",
      "max_depth: 37, min_samples_split: 482, rmse: 0.056447\n"
     ]
    }
   ],
   "source": [
    "max_depths = np.arange(2, 40, 5)\n",
    "min_samples_splits = np.arange(2, 500, 20)\n",
    "\n",
    "rmses = np.zeros((len(max_depths), len(min_samples_splits)))\n",
    "\n",
    "for i, max_depth in enumerate(max_depths):\n",
    "    for j, min_samples_split in enumerate(min_samples_splits):\n",
    "        cv_rmse = evaluate_model(DecisionTreeRegressor,\n",
    "                                 max_depth=max_depth,\n",
    "                                 min_samples_split=min_samples_split)\n",
    "        print(f\"max_depth: {max_depth}, min_samples_split: {min_samples_split}, rmse: {cv_rmse:.6f}\")\n",
    "        rmses[i, j] = cv_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84f45847-bb17-4c1d-bc9a-b2cf6b86cc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(rmses, \n",
    "            xticklabels=min_samples_splits,\n",
    "            yticklabels=max_depths,\n",
    "            cmap=\"viridis\", \n",
    "            fmt=\".2f\")\n",
    "\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"max_depth\")\n",
    "plt.title(\"Decision Tree CV RMSE Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ec10a381-2252-47ea-ab70-704f82454109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 21)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unravel_index(np.argmin(rmses), rmses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c1eb70dc-b63f-411a-8ea6-386f5a4cc245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05638241152007821"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmses[2][21]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4707c247-34b1-400d-8087-9e7864df3eff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Random Forst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5a425ab1-f18d-40f6-92b7-544d155394f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0b863417-834c-4a1f-b21c-7322a044b995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, rmse: 0.059148\n",
      "fold: 1, rmse: 0.059490\n",
      "fold: 2, rmse: 0.058975\n",
      "fold: 3, rmse: 0.058966\n",
      "fold: 4, rmse: 0.058859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05908786009723153"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(RandomForestRegressor, max_features='sqrt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d108d450-816f-4442-ba98-055f431b4ebb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Random Forst + noise, feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3ba743-4fa0-482a-932c-9d31e1e172ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cd8b166-9e5e-4184-bd23-e040b01b972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d2bce6-fd80-4583-a858-88ddedde5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_copy = X.copy()\n",
    "X_copy['noise'] = np.random.normal(0, 0.5, X.iloc[:, 0].shape)\n",
    "\n",
    "X_noise_train, X_noise_test, y_noise_train, y_noise_test = train_test_split(X_copy, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "983b8b32-7704-4459-bdf5-2b2e51e7378e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05772420102039242"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestRegressor(max_features='sqrt')\n",
    "clf.fit(X_noise_train, y_noise_train)\n",
    "y_noise_pred = clf.predict(X_noise_test)\n",
    "root_mean_squared_error(y_noise_test, y_noise_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "257d69e3-5de3-49e2-a81a-0b920bf37e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='feature_importances', ylabel='feature_names'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {\n",
    "    \"feature_importances\": clf.feature_importances_,\n",
    "    \"feature_names\": clf.feature_names_in_,\n",
    "}\n",
    "sns.barplot(data=data, x='feature_importances', y='feature_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6470d04-1175-45ba-84aa-b7d244f65d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importances</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_names</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>curvature</th>\n",
       "      <td>0.304897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed_limit</th>\n",
       "      <td>0.252762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_reported_accidents</th>\n",
       "      <td>0.069109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lighting_night</th>\n",
       "      <td>0.207965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature_importances\n",
       "feature_names                              \n",
       "curvature                          0.304897\n",
       "speed_limit                        0.252762\n",
       "num_reported_accidents             0.069109\n",
       "lighting_night                     0.207965"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fi = pd.DataFrame(data)\n",
    "df_fi = df_fi.set_index('feature_names')\n",
    "selected_features = df_fi[df_fi > df_fi.loc['noise'].iloc[0]].dropna()\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd4656f-df55-4149-99ff-9b92cbc3e627",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Random Forest and Selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72b7811b-f57f-4997-9106-fbcc36fdbdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf2da193-5f42-456d-8b49-813e11194672",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_names = selected_features.index\n",
    "\n",
    "X_selected = X.loc[:, selected_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf70e658-127e-4f36-934e-35f4ae42c1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, rmse: 0.070764\n",
      "fold: 1, rmse: 0.070396\n",
      "fold: 2, rmse: 0.070678\n",
      "fold: 3, rmse: 0.070872\n",
      "fold: 4, rmse: 0.070716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07068511307153134"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(RandomForestRegressor, X_selected, max_features='sqrt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6021e22e-bf84-4c2b-b3ef-5c15585ba23d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### SVM + w/selection_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "35f80314-d58f-4ced-ae92-46f0731487b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f86b38-3557-45e8-871d-1913023e848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(SVR, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca91441b-ace2-46e1-bd80-47b41f33f836",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3d876c5-f7e6-4b56-8c22-d6c7dc370d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "574284b4-eda0-400c-96a9-f41a9900d9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, rmse: 0.057106\n",
      "fold: 1, rmse: 0.056844\n",
      "fold: 2, rmse: 0.056968\n",
      "fold: 3, rmse: 0.056442\n",
      "fold: 4, rmse: 0.056935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05685897968259945"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(XGBRegressor, X, n_estimators=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbbe659-6091-4bc0-ac7d-d3b78f90b79e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "283e3eb7-c6c2-4ba3-af71-5270ec50e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a667ca1-da04-45f7-b1c1-035cc47513d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352580\n",
      "fold: 0, rmse: 0.056453\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352248\n",
      "fold: 1, rmse: 0.056515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 165\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352505\n",
      "fold: 2, rmse: 0.056520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 170\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352283\n",
      "fold: 3, rmse: 0.056680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352272\n",
      "fold: 4, rmse: 0.056641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05656192750201241"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(LGBMRegressor, X, n_estimators=500, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9f70d7-d5da-4cd5-b08d-dd3aa1a220a2",
   "metadata": {},
   "source": [
    "## Parameter tuning (Optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d6044c0-ff75-4396-888a-dd3c3b7a5fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04637e2b-c59d-484a-a810-751e2f40d6af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee32096-ca4a-4a2b-bccf-931e7b801263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f7ffd3-578a-4b36-9334-8224ff757519",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f4436be-2c7f-4bc5-9041-5d250a9e6209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fee9bf4-2e66-4fb4-b27d-21ff12ec400b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffddfd29-befb-43c8-8835-925f44f326fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b560c518-386f-4739-9337-1b69aaeab2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 1000)\n",
    "    min_samples_split =  trial.suggest_int('min_samples_split', 2, 500)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 200)\n",
    "\n",
    "    clf = DecisionTreeRegressor(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "    )\n",
    "    \n",
    "    rmses = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train = X.iloc[train_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        X_test = X.iloc[test_index]\n",
    "        y_test = y.iloc[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        rmse = root_mean_squared_error(y_pred, y_test)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32a3d0ab-275d-456e-a0c8-38a018af218e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 18:33:07,478] A new study created in memory with name: no-name-58dab873-7586-4277-98c4-370422071089\n",
      "[I 2025-10-21 18:33:10,821] Trial 0 finished with value: 0.056667099244816485 and parameters: {'max_depth': 655, 'min_samples_split': 480, 'min_samples_leaf': 179}. Best is trial 0 with value: 0.056667099244816485.\n",
      "[I 2025-10-21 18:33:14,403] Trial 1 finished with value: 0.056642423432641045 and parameters: {'max_depth': 841, 'min_samples_split': 459, 'min_samples_leaf': 64}. Best is trial 1 with value: 0.056642423432641045.\n",
      "[I 2025-10-21 18:33:18,291] Trial 2 finished with value: 0.05713840811356443 and parameters: {'max_depth': 301, 'min_samples_split': 132, 'min_samples_leaf': 16}. Best is trial 1 with value: 0.056642423432641045.\n",
      "[I 2025-10-21 18:33:21,949] Trial 3 finished with value: 0.05679002100605024 and parameters: {'max_depth': 332, 'min_samples_split': 261, 'min_samples_leaf': 139}. Best is trial 1 with value: 0.056642423432641045.\n",
      "[I 2025-10-21 18:33:25,739] Trial 4 finished with value: 0.05677455401825765 and parameters: {'max_depth': 445, 'min_samples_split': 303, 'min_samples_leaf': 99}. Best is trial 1 with value: 0.056642423432641045.\n",
      "[I 2025-10-21 18:33:29,083] Trial 5 finished with value: 0.05669662879189415 and parameters: {'max_depth': 179, 'min_samples_split': 215, 'min_samples_leaf': 198}. Best is trial 1 with value: 0.056642423432641045.\n",
      "[I 2025-10-21 18:33:32,738] Trial 6 finished with value: 0.056992291345776394 and parameters: {'max_depth': 890, 'min_samples_split': 167, 'min_samples_leaf': 82}. Best is trial 1 with value: 0.056642423432641045.\n",
      "[I 2025-10-21 18:33:36,067] Trial 7 finished with value: 0.05663786317308915 and parameters: {'max_depth': 151, 'min_samples_split': 482, 'min_samples_leaf': 80}. Best is trial 7 with value: 0.05663786317308915.\n",
      "[I 2025-10-21 18:33:39,419] Trial 8 finished with value: 0.056723346388090824 and parameters: {'max_depth': 614, 'min_samples_split': 346, 'min_samples_leaf': 168}. Best is trial 7 with value: 0.05663786317308915.\n",
      "[I 2025-10-21 18:33:42,856] Trial 9 finished with value: 0.05671855018057152 and parameters: {'max_depth': 815, 'min_samples_split': 141, 'min_samples_leaf': 167}. Best is trial 7 with value: 0.05663786317308915.\n",
      "[I 2025-10-21 18:33:46,786] Trial 10 finished with value: 0.05761149331876745 and parameters: {'max_depth': 94, 'min_samples_split': 41, 'min_samples_leaf': 37}. Best is trial 7 with value: 0.05663786317308915.\n",
      "[I 2025-10-21 18:33:50,124] Trial 11 finished with value: 0.05664073987015763 and parameters: {'max_depth': 20, 'min_samples_split': 491, 'min_samples_leaf': 61}. Best is trial 7 with value: 0.05663786317308915.\n",
      "[I 2025-10-21 18:33:53,606] Trial 12 finished with value: 0.05664045791074988 and parameters: {'max_depth': 19, 'min_samples_split': 409, 'min_samples_leaf': 57}. Best is trial 7 with value: 0.05663786317308915.\n",
      "[I 2025-10-21 18:33:57,156] Trial 13 finished with value: 0.0567259982295687 and parameters: {'max_depth': 182, 'min_samples_split': 370, 'min_samples_leaf': 123}. Best is trial 7 with value: 0.05663786317308915.\n",
      "[I 2025-10-21 18:33:58,586] Trial 14 finished with value: 0.07670806788752485 and parameters: {'max_depth': 4, 'min_samples_split': 405, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.05663786317308915.\n",
      "[I 2025-10-21 18:34:02,057] Trial 15 finished with value: 0.05661951432588934 and parameters: {'max_depth': 262, 'min_samples_split': 425, 'min_samples_leaf': 45}. Best is trial 15 with value: 0.05661951432588934.\n",
      "[I 2025-10-21 18:34:05,461] Trial 16 finished with value: 0.056568223899178094 and parameters: {'max_depth': 305, 'min_samples_split': 438, 'min_samples_leaf': 31}. Best is trial 16 with value: 0.056568223899178094.\n",
      "[I 2025-10-21 18:34:09,548] Trial 17 finished with value: 0.056651427944646116 and parameters: {'max_depth': 346, 'min_samples_split': 306, 'min_samples_leaf': 32}. Best is trial 16 with value: 0.056568223899178094.\n",
      "[I 2025-10-21 18:34:13,180] Trial 18 finished with value: 0.0565874955678326 and parameters: {'max_depth': 485, 'min_samples_split': 423, 'min_samples_leaf': 38}. Best is trial 16 with value: 0.056568223899178094.\n",
      "[I 2025-10-21 18:34:16,920] Trial 19 finished with value: 0.056482329944290956 and parameters: {'max_depth': 510, 'min_samples_split': 345, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:34:20,982] Trial 20 finished with value: 0.05649491967360878 and parameters: {'max_depth': 597, 'min_samples_split': 353, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:34:24,989] Trial 21 finished with value: 0.05652239284740035 and parameters: {'max_depth': 613, 'min_samples_split': 343, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:34:28,737] Trial 22 finished with value: 0.05652359134917835 and parameters: {'max_depth': 622, 'min_samples_split': 339, 'min_samples_leaf': 4}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:34:32,526] Trial 23 finished with value: 0.056710709898948185 and parameters: {'max_depth': 725, 'min_samples_split': 258, 'min_samples_leaf': 19}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:34:36,210] Trial 24 finished with value: 0.056539243833459006 and parameters: {'max_depth': 546, 'min_samples_split': 298, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:34:39,730] Trial 25 finished with value: 0.056554739209361084 and parameters: {'max_depth': 436, 'min_samples_split': 375, 'min_samples_leaf': 18}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:34:43,462] Trial 26 finished with value: 0.05675991314265272 and parameters: {'max_depth': 733, 'min_samples_split': 227, 'min_samples_leaf': 14}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:34:46,972] Trial 27 finished with value: 0.056714578319070584 and parameters: {'max_depth': 974, 'min_samples_split': 336, 'min_samples_leaf': 51}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:34:50,511] Trial 28 finished with value: 0.05657558699232956 and parameters: {'max_depth': 561, 'min_samples_split': 365, 'min_samples_leaf': 23}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:34:54,063] Trial 29 finished with value: 0.056791827555047955 and parameters: {'max_depth': 706, 'min_samples_split': 282, 'min_samples_leaf': 77}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:34:57,643] Trial 30 finished with value: 0.05681569055096823 and parameters: {'max_depth': 418, 'min_samples_split': 189, 'min_samples_leaf': 125}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:01,270] Trial 31 finished with value: 0.05653255144224504 and parameters: {'max_depth': 626, 'min_samples_split': 323, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:04,799] Trial 32 finished with value: 0.05649544461235845 and parameters: {'max_depth': 567, 'min_samples_split': 387, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:08,317] Trial 33 finished with value: 0.05653401028421996 and parameters: {'max_depth': 523, 'min_samples_split': 385, 'min_samples_leaf': 14}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:11,813] Trial 34 finished with value: 0.05654177367404371 and parameters: {'max_depth': 674, 'min_samples_split': 448, 'min_samples_leaf': 27}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:15,494] Trial 35 finished with value: 0.05665980673694786 and parameters: {'max_depth': 574, 'min_samples_split': 272, 'min_samples_leaf': 12}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:18,960] Trial 36 finished with value: 0.05660125190307441 and parameters: {'max_depth': 787, 'min_samples_split': 462, 'min_samples_leaf': 46}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:22,512] Trial 37 finished with value: 0.056684404198925134 and parameters: {'max_depth': 367, 'min_samples_split': 397, 'min_samples_leaf': 71}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:26,183] Trial 38 finished with value: 0.0569082403109807 and parameters: {'max_depth': 494, 'min_samples_split': 3, 'min_samples_leaf': 103}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:29,889] Trial 39 finished with value: 0.056708136712335565 and parameters: {'max_depth': 670, 'min_samples_split': 242, 'min_samples_leaf': 12}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:33,427] Trial 40 finished with value: 0.05672723365717654 and parameters: {'max_depth': 409, 'min_samples_split': 355, 'min_samples_leaf': 99}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:37,079] Trial 41 finished with value: 0.05652203757585959 and parameters: {'max_depth': 601, 'min_samples_split': 324, 'min_samples_leaf': 5}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:40,706] Trial 42 finished with value: 0.056621139020428965 and parameters: {'max_depth': 586, 'min_samples_split': 314, 'min_samples_leaf': 24}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:44,385] Trial 43 finished with value: 0.056576912183342355 and parameters: {'max_depth': 768, 'min_samples_split': 286, 'min_samples_leaf': 7}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:47,970] Trial 44 finished with value: 0.05664431825027394 and parameters: {'max_depth': 654, 'min_samples_split': 335, 'min_samples_leaf': 39}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:51,723] Trial 45 finished with value: 0.05655510942891277 and parameters: {'max_depth': 477, 'min_samples_split': 387, 'min_samples_leaf': 25}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:55,162] Trial 46 finished with value: 0.05669835627597571 and parameters: {'max_depth': 607, 'min_samples_split': 361, 'min_samples_leaf': 196}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:35:58,774] Trial 47 finished with value: 0.056548862767636675 and parameters: {'max_depth': 893, 'min_samples_split': 319, 'min_samples_leaf': 11}. Best is trial 19 with value: 0.056482329944290956.\n",
      "[I 2025-10-21 18:36:02,309] Trial 48 finished with value: 0.056436533549953406 and parameters: {'max_depth': 522, 'min_samples_split': 469, 'min_samples_leaf': 1}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:36:05,845] Trial 49 finished with value: 0.05654843592477514 and parameters: {'max_depth': 532, 'min_samples_split': 498, 'min_samples_leaf': 33}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:36:09,341] Trial 50 finished with value: 0.05651676147575777 and parameters: {'max_depth': 459, 'min_samples_split': 471, 'min_samples_leaf': 20}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:36:12,886] Trial 51 finished with value: 0.05649999787156858 and parameters: {'max_depth': 388, 'min_samples_split': 474, 'min_samples_leaf': 19}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:36:16,400] Trial 52 finished with value: 0.05650944218766888 and parameters: {'max_depth': 242, 'min_samples_split': 476, 'min_samples_leaf': 21}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:36:19,980] Trial 53 finished with value: 0.05648660749266262 and parameters: {'max_depth': 253, 'min_samples_split': 435, 'min_samples_leaf': 10}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:36:23,549] Trial 54 finished with value: 0.05669267907701013 and parameters: {'max_depth': 389, 'min_samples_split': 425, 'min_samples_leaf': 148}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:36:27,060] Trial 55 finished with value: 0.056476963339452665 and parameters: {'max_depth': 271, 'min_samples_split': 455, 'min_samples_leaf': 8}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:36:30,495] Trial 56 finished with value: 0.05659891391970996 and parameters: {'max_depth': 90, 'min_samples_split': 444, 'min_samples_leaf': 43}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:36:33,988] Trial 57 finished with value: 0.05649257790964636 and parameters: {'max_depth': 280, 'min_samples_split': 415, 'min_samples_leaf': 8}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:36:37,428] Trial 58 finished with value: 0.05655370062856311 and parameters: {'max_depth': 251, 'min_samples_split': 426, 'min_samples_leaf': 29}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:36:40,856] Trial 59 finished with value: 0.05662840621882439 and parameters: {'max_depth': 196, 'min_samples_split': 404, 'min_samples_leaf': 55}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:36:44,326] Trial 60 finished with value: 0.05647591849927388 and parameters: {'max_depth': 314, 'min_samples_split': 452, 'min_samples_leaf': 8}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:36:47,865] Trial 61 finished with value: 0.05649448285982657 and parameters: {'max_depth': 303, 'min_samples_split': 455, 'min_samples_leaf': 9}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:36:51,326] Trial 62 finished with value: 0.05647846855183112 and parameters: {'max_depth': 304, 'min_samples_split': 455, 'min_samples_leaf': 9}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:36:54,739] Trial 63 finished with value: 0.05652582599085275 and parameters: {'max_depth': 334, 'min_samples_split': 500, 'min_samples_leaf': 16}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:36:58,175] Trial 64 finished with value: 0.0565693972760293 and parameters: {'max_depth': 134, 'min_samples_split': 438, 'min_samples_leaf': 34}. Best is trial 48 with value: 0.056436533549953406.\n",
      "[I 2025-10-21 18:37:01,645] Trial 65 finished with value: 0.056404489125154236 and parameters: {'max_depth': 205, 'min_samples_split': 485, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:37:05,169] Trial 66 finished with value: 0.056532065067151985 and parameters: {'max_depth': 216, 'min_samples_split': 462, 'min_samples_leaf': 28}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:37:09,420] Trial 67 finished with value: 0.05749173008464793 and parameters: {'max_depth': 158, 'min_samples_split': 92, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:37:12,836] Trial 68 finished with value: 0.05666392954805634 and parameters: {'max_depth': 90, 'min_samples_split': 482, 'min_samples_leaf': 89}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:37:16,252] Trial 69 finished with value: 0.05652431547725082 and parameters: {'max_depth': 209, 'min_samples_split': 486, 'min_samples_leaf': 18}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:37:19,749] Trial 70 finished with value: 0.05649783060853266 and parameters: {'max_depth': 326, 'min_samples_split': 440, 'min_samples_leaf': 9}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:37:23,305] Trial 71 finished with value: 0.05649166363121507 and parameters: {'max_depth': 256, 'min_samples_split': 414, 'min_samples_leaf': 7}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:37:26,830] Trial 72 finished with value: 0.056502529940480405 and parameters: {'max_depth': 268, 'min_samples_split': 456, 'min_samples_leaf': 15}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:37:30,411] Trial 73 finished with value: 0.05648041141368326 and parameters: {'max_depth': 125, 'min_samples_split': 426, 'min_samples_leaf': 6}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:37:33,936] Trial 74 finished with value: 0.05642124765146343 and parameters: {'max_depth': 135, 'min_samples_split': 466, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:37:37,465] Trial 75 finished with value: 0.056438805315727314 and parameters: {'max_depth': 35, 'min_samples_split': 467, 'min_samples_leaf': 3}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:37:41,050] Trial 76 finished with value: 0.056545105862286504 and parameters: {'max_depth': 126, 'min_samples_split': 463, 'min_samples_leaf': 23}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:37:44,644] Trial 77 finished with value: 0.05644468230076426 and parameters: {'max_depth': 49, 'min_samples_split': 485, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:37:48,226] Trial 78 finished with value: 0.05650721687982112 and parameters: {'max_depth': 56, 'min_samples_split': 488, 'min_samples_leaf': 15}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:37:51,834] Trial 79 finished with value: 0.05642012303686017 and parameters: {'max_depth': 35, 'min_samples_split': 473, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:37:55,521] Trial 80 finished with value: 0.05641474785624333 and parameters: {'max_depth': 46, 'min_samples_split': 470, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:37:59,177] Trial 81 finished with value: 0.05644808123600127 and parameters: {'max_depth': 46, 'min_samples_split': 472, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:02,773] Trial 82 finished with value: 0.05644174339767666 and parameters: {'max_depth': 36, 'min_samples_split': 476, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:06,393] Trial 83 finished with value: 0.056455581977366345 and parameters: {'max_depth': 44, 'min_samples_split': 471, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:07,188] Trial 84 finished with value: 0.11866727042554222 and parameters: {'max_depth': 2, 'min_samples_split': 490, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:10,637] Trial 85 finished with value: 0.05647864581587629 and parameters: {'max_depth': 50, 'min_samples_split': 500, 'min_samples_leaf': 14}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:14,196] Trial 86 finished with value: 0.056443476529775036 and parameters: {'max_depth': 27, 'min_samples_split': 481, 'min_samples_leaf': 4}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:17,766] Trial 87 finished with value: 0.05649897247414024 and parameters: {'max_depth': 76, 'min_samples_split': 484, 'min_samples_leaf': 14}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:21,262] Trial 88 finished with value: 0.05643327872053242 and parameters: {'max_depth': 31, 'min_samples_split': 467, 'min_samples_leaf': 5}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:24,730] Trial 89 finished with value: 0.05650915652311376 and parameters: {'max_depth': 18, 'min_samples_split': 466, 'min_samples_leaf': 22}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:28,347] Trial 90 finished with value: 0.05646297840531174 and parameters: {'max_depth': 110, 'min_samples_split': 434, 'min_samples_leaf': 6}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:31,887] Trial 91 finished with value: 0.0564660459342969 and parameters: {'max_depth': 29, 'min_samples_split': 476, 'min_samples_leaf': 5}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:35,365] Trial 92 finished with value: 0.0565023011686388 and parameters: {'max_depth': 76, 'min_samples_split': 490, 'min_samples_leaf': 12}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:38,850] Trial 93 finished with value: 0.056533066702100586 and parameters: {'max_depth': 166, 'min_samples_split': 480, 'min_samples_leaf': 18}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:42,465] Trial 94 finished with value: 0.05646633633371775 and parameters: {'max_depth': 24, 'min_samples_split': 446, 'min_samples_leaf': 4}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:46,341] Trial 95 finished with value: 0.05652141068124147 and parameters: {'max_depth': 69, 'min_samples_split': 500, 'min_samples_leaf': 27}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:49,904] Trial 96 finished with value: 0.056423550393616795 and parameters: {'max_depth': 105, 'min_samples_split': 464, 'min_samples_leaf': 4}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:53,381] Trial 97 finished with value: 0.05669157935700786 and parameters: {'max_depth': 112, 'min_samples_split': 464, 'min_samples_leaf': 111}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:38:57,111] Trial 98 finished with value: 0.056513565227602355 and parameters: {'max_depth': 147, 'min_samples_split': 446, 'min_samples_leaf': 18}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:00,762] Trial 99 finished with value: 0.05651544121071354 and parameters: {'max_depth': 102, 'min_samples_split': 418, 'min_samples_leaf': 11}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:01,662] Trial 100 finished with value: 0.11866739192197565 and parameters: {'max_depth': 2, 'min_samples_split': 396, 'min_samples_leaf': 6}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:05,404] Trial 101 finished with value: 0.05643112176312295 and parameters: {'max_depth': 63, 'min_samples_split': 481, 'min_samples_leaf': 4}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:09,114] Trial 102 finished with value: 0.056505134902413066 and parameters: {'max_depth': 70, 'min_samples_split': 469, 'min_samples_leaf': 12}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:12,584] Trial 103 finished with value: 0.05668116611201653 and parameters: {'max_depth': 22, 'min_samples_split': 478, 'min_samples_leaf': 145}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:16,270] Trial 104 finished with value: 0.05648557045442881 and parameters: {'max_depth': 81, 'min_samples_split': 434, 'min_samples_leaf': 5}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:19,909] Trial 105 finished with value: 0.056448236352797 and parameters: {'max_depth': 29, 'min_samples_split': 451, 'min_samples_leaf': 4}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:23,549] Trial 106 finished with value: 0.05651226856338889 and parameters: {'max_depth': 182, 'min_samples_split': 495, 'min_samples_leaf': 22}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:27,002] Trial 107 finished with value: 0.05663057891624553 and parameters: {'max_depth': 101, 'min_samples_split': 465, 'min_samples_leaf': 65}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:30,579] Trial 108 finished with value: 0.05667955872890943 and parameters: {'max_depth': 65, 'min_samples_split': 458, 'min_samples_leaf': 161}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:34,172] Trial 109 finished with value: 0.056516811439132356 and parameters: {'max_depth': 125, 'min_samples_split': 432, 'min_samples_leaf': 15}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:37,753] Trial 110 finished with value: 0.05648566357874372 and parameters: {'max_depth': 46, 'min_samples_split': 478, 'min_samples_leaf': 11}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:41,385] Trial 111 finished with value: 0.05645114901206614 and parameters: {'max_depth': 37, 'min_samples_split': 492, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:45,057] Trial 112 finished with value: 0.05642649901586312 and parameters: {'max_depth': 92, 'min_samples_split': 483, 'min_samples_leaf': 4}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:48,852] Trial 113 finished with value: 0.056476812036255895 and parameters: {'max_depth': 147, 'min_samples_split': 448, 'min_samples_leaf': 9}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:52,696] Trial 114 finished with value: 0.056886699604550284 and parameters: {'max_depth': 95, 'min_samples_split': 181, 'min_samples_leaf': 18}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:56,153] Trial 115 finished with value: 0.056439142548606394 and parameters: {'max_depth': 13, 'min_samples_split': 469, 'min_samples_leaf': 5}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:39:57,603] Trial 116 finished with value: 0.07671535595893525 and parameters: {'max_depth': 4, 'min_samples_split': 94, 'min_samples_leaf': 11}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:40:01,445] Trial 117 finished with value: 0.05645596338919554 and parameters: {'max_depth': 67, 'min_samples_split': 461, 'min_samples_leaf': 5}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:40:05,187] Trial 118 finished with value: 0.056521494018059636 and parameters: {'max_depth': 167, 'min_samples_split': 471, 'min_samples_leaf': 15}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:40:08,760] Trial 119 finished with value: 0.05653904076950772 and parameters: {'max_depth': 121, 'min_samples_split': 444, 'min_samples_leaf': 25}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:40:12,370] Trial 120 finished with value: 0.05646357074343296 and parameters: {'max_depth': 226, 'min_samples_split': 491, 'min_samples_leaf': 8}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:40:16,017] Trial 121 finished with value: 0.05645751322226705 and parameters: {'max_depth': 19, 'min_samples_split': 475, 'min_samples_leaf': 5}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:40:19,693] Trial 122 finished with value: 0.056443456932806266 and parameters: {'max_depth': 88, 'min_samples_split': 484, 'min_samples_leaf': 4}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:40:23,309] Trial 123 finished with value: 0.056437806966274165 and parameters: {'max_depth': 91, 'min_samples_split': 457, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:40:27,066] Trial 124 finished with value: 0.05643986954950876 and parameters: {'max_depth': 56, 'min_samples_split': 457, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:40:30,693] Trial 125 finished with value: 0.056502904842148774 and parameters: {'max_depth': 150, 'min_samples_split': 453, 'min_samples_leaf': 11}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:40:34,303] Trial 126 finished with value: 0.0564851702226429 and parameters: {'max_depth': 61, 'min_samples_split': 406, 'min_samples_leaf': 8}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:40:38,332] Trial 127 finished with value: 0.05646937197897348 and parameters: {'max_depth': 507, 'min_samples_split': 425, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:40:42,057] Trial 128 finished with value: 0.05652793088920627 and parameters: {'max_depth': 137, 'min_samples_split': 461, 'min_samples_leaf': 16}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:40:45,925] Trial 129 finished with value: 0.0565555213685109 and parameters: {'max_depth': 105, 'min_samples_split': 440, 'min_samples_leaf': 21}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:40:49,849] Trial 130 finished with value: 0.05650373414400567 and parameters: {'max_depth': 186, 'min_samples_split': 457, 'min_samples_leaf': 12}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:40:53,473] Trial 131 finished with value: 0.056434374132889265 and parameters: {'max_depth': 47, 'min_samples_split': 470, 'min_samples_leaf': 4}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:40:57,093] Trial 132 finished with value: 0.056475718275635 and parameters: {'max_depth': 56, 'min_samples_split': 468, 'min_samples_leaf': 7}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:00,676] Trial 133 finished with value: 0.05641482373271687 and parameters: {'max_depth': 79, 'min_samples_split': 500, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:04,253] Trial 134 finished with value: 0.05644156329457276 and parameters: {'max_depth': 93, 'min_samples_split': 499, 'min_samples_leaf': 5}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:07,823] Trial 135 finished with value: 0.05647400793537104 and parameters: {'max_depth': 85, 'min_samples_split': 488, 'min_samples_leaf': 9}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:10,453] Trial 136 finished with value: 0.05689148047446589 and parameters: {'max_depth': 8, 'min_samples_split': 483, 'min_samples_leaf': 13}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:14,150] Trial 137 finished with value: 0.056433497059572124 and parameters: {'max_depth': 115, 'min_samples_split': 491, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:17,802] Trial 138 finished with value: 0.05668039966068892 and parameters: {'max_depth': 110, 'min_samples_split': 490, 'min_samples_leaf': 129}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:21,486] Trial 139 finished with value: 0.056705690614989465 and parameters: {'max_depth': 78, 'min_samples_split': 209, 'min_samples_leaf': 188}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:25,288] Trial 140 finished with value: 0.05644016193955111 and parameters: {'max_depth': 130, 'min_samples_split': 499, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:28,954] Trial 141 finished with value: 0.056478365250792896 and parameters: {'max_depth': 35, 'min_samples_split': 469, 'min_samples_leaf': 6}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:32,676] Trial 142 finished with value: 0.0564435183369328 and parameters: {'max_depth': 51, 'min_samples_split': 477, 'min_samples_leaf': 5}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:36,282] Trial 143 finished with value: 0.0564751391127418 and parameters: {'max_depth': 78, 'min_samples_split': 471, 'min_samples_leaf': 9}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:39,823] Trial 144 finished with value: 0.05643408062245779 and parameters: {'max_depth': 542, 'min_samples_split': 486, 'min_samples_leaf': 4}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:43,369] Trial 145 finished with value: 0.05651506511603076 and parameters: {'max_depth': 116, 'min_samples_split': 480, 'min_samples_leaf': 15}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:46,987] Trial 146 finished with value: 0.056425291845908734 and parameters: {'max_depth': 552, 'min_samples_split': 490, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:50,559] Trial 147 finished with value: 0.05640942601348542 and parameters: {'max_depth': 535, 'min_samples_split': 492, 'min_samples_leaf': 1}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:54,208] Trial 148 finished with value: 0.05646454351842328 and parameters: {'max_depth': 481, 'min_samples_split': 491, 'min_samples_leaf': 10}. Best is trial 65 with value: 0.056404489125154236.\n",
      "[I 2025-10-21 18:41:57,730] Trial 149 finished with value: 0.056633939803778385 and parameters: {'max_depth': 539, 'min_samples_split': 500, 'min_samples_leaf': 86}. Best is trial 65 with value: 0.056404489125154236.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01051f7-d81f-4792-aac0-b68c9cad7ead",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Full train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ed1bce34-757b-4985-acb9-3f084bcbee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeRegressor(**study.best_params)\n",
    "clf.fit(X, y)\n",
    "\n",
    "submission = submission_generator(clf, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce2a895-3843-44be-9a3b-d39cc22d5a25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c3cd3aa1-feff-4c3c-9754-c3320490cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8b7dd3-7be6-4766-9083-04ce5f09c634",
   "metadata": {},
   "source": [
    "#### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "50d543e3-7d27-4f36-ab0b-00182dd42471",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a08b2495-4e47-493b-b0e9-643cd081f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trials):\n",
    "    n_estimators = trials.suggest_int('n_estimator', 5, 500)\n",
    "    max_depth = trials.suggest_int('max_depth', 2, 500)\n",
    "    min_samples_split = trials.suggest_int('min_samples_split', 1, 500)\n",
    "    min_samples_leaf = trials.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trials.suggest_categorical('max_features', ['sqrt', 'log2'])\n",
    "\n",
    "    clf = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        \n",
    "    )\n",
    "    \n",
    "    rmses = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train = X.iloc[train_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        X_test = X.iloc[test_index]\n",
    "        y_test = y.iloc[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        rmse = root_mean_squared_error(y_pred, y_test)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8b955de1-0e42-4f21-a7a1-adf5c1563521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:13:43,109] A new study created in memory with name: no-name-c2487df3-08ae-4d07-9a6d-941d4e5aa990\n",
      "[I 2025-10-21 19:14:41,721] Trial 0 finished with value: 0.05863571985038685 and parameters: {'n_estimator': 84, 'max_depth': 125, 'min_samples_split': 268, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.05863571985038685.\n",
      "[I 2025-10-21 19:16:12,806] Trial 1 finished with value: 0.05855783229788797 and parameters: {'n_estimator': 127, 'max_depth': 222, 'min_samples_split': 260, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 1 with value: 0.05855783229788797.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa79d1c1-4ca2-482b-a7fb-b2ae8e2b042d",
   "metadata": {},
   "source": [
    "#### Full train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459d13fe-33c2-4404-9d6d-a219f71ec35a",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b5254999-c5c1-4ed8-b9ca-63f312121b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1f6cb1-5721-45e1-ba6f-0f87625dcd51",
   "metadata": {},
   "source": [
    "#### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "59e7d5dd-3ff7-4ece-a837-f7c09b2a480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a29247d8-5ffd-42ab-a133-23dc7e9444f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trials):\n",
    "    num_leaves = trials.suggest_int('num_leaves', 4, 256)\n",
    "    max_depth = trials.suggest_int('max_depth', -1, 512)\n",
    "    learning_rate = trials.suggest_float('learning_rate', 0.003, 0.3)\n",
    "    n_estimators = trials.suggest_int('n_estimator', 24, 1024)\n",
    "\n",
    "    clf = LGBMRegressor(\n",
    "        num_leaves=num_leaves,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "    )\n",
    "\n",
    "    rmses = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train = X.iloc[train_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        X_test = X.iloc[test_index]\n",
    "        y_test = y.iloc[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        rmse = root_mean_squared_error(y_pred, y_test)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508c9438-a2ba-43f3-9682-b1ea4064a0fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:25:24,988] A new study created in memory with name: no-name-a0318067-f316-46c9-a905-925ff101e236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352436\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352466\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352325\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352548\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:25:39,324] Trial 0 finished with value: 0.05612007265756238 and parameters: {'num_leaves': 65, 'max_depth': 396, 'learning_rate': 0.08565903020702009, 'n_estimator': 487}. Best is trial 0 with value: 0.05612007265756238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352410\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352339\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:25:46,352] Trial 1 finished with value: 0.05616703072326375 and parameters: {'num_leaves': 28, 'max_depth': 15, 'learning_rate': 0.15212418720728402, 'n_estimator': 320}. Best is trial 0 with value: 0.05612007265756238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352343\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352502\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352382\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 170\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:25:53,017] Trial 2 finished with value: 0.05679087150170818 and parameters: {'num_leaves': 239, 'max_depth': 308, 'learning_rate': 0.29945545787910993, 'n_estimator': 163}. Best is trial 0 with value: 0.05612007265756238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352336\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352684\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352297\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:25:58,273] Trial 3 finished with value: 0.05618176314120562 and parameters: {'num_leaves': 61, 'max_depth': 362, 'learning_rate': 0.22360933531084823, 'n_estimator': 182}. Best is trial 0 with value: 0.05612007265756238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 169\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352473\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352219\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352538\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 170\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352348\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:26:16,539] Trial 4 finished with value: 0.05769329782020727 and parameters: {'num_leaves': 167, 'max_depth': 41, 'learning_rate': 0.2821377479349702, 'n_estimator': 574}. Best is trial 0 with value: 0.05612007265756238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352441\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352340\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352238\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352414\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:26:23,664] Trial 5 finished with value: 0.05613796515995886 and parameters: {'num_leaves': 58, 'max_depth': 310, 'learning_rate': 0.15268584075364164, 'n_estimator': 247}. Best is trial 0 with value: 0.05612007265756238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352513\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352268\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:26:48,412] Trial 6 finished with value: 0.05637289906514299 and parameters: {'num_leaves': 87, 'max_depth': 264, 'learning_rate': 0.15194034948901958, 'n_estimator': 580}. Best is trial 0 with value: 0.05612007265756238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352406\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352392\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352361\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352178\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:27:12,783] Trial 7 finished with value: 0.057371754135598765 and parameters: {'num_leaves': 180, 'max_depth': 85, 'learning_rate': 0.26124799740568694, 'n_estimator': 486}. Best is trial 0 with value: 0.05612007265756238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352328\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 180\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352463\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352265\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352459\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:27:44,559] Trial 8 finished with value: 0.05603844107634207 and parameters: {'num_leaves': 140, 'max_depth': 303, 'learning_rate': 0.01760958646507478, 'n_estimator': 545}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352472\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352356\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352328\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352256\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:28:07,398] Trial 9 finished with value: 0.057765884675277115 and parameters: {'num_leaves': 129, 'max_depth': 247, 'learning_rate': 0.2645592301838523, 'n_estimator': 865}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352392\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 170\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352381\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352530\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 169\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:28:53,096] Trial 10 finished with value: 0.056042843796101326 and parameters: {'num_leaves': 122, 'max_depth': 507, 'learning_rate': 0.010389304616184007, 'n_estimator': 989}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352347\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352181\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352503\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:29:37,279] Trial 11 finished with value: 0.0560490771547306 and parameters: {'num_leaves': 124, 'max_depth': 498, 'learning_rate': 0.008387668456637805, 'n_estimator': 1015}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352691\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352372\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352282\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:30:27,907] Trial 12 finished with value: 0.05611359090484206 and parameters: {'num_leaves': 179, 'max_depth': 493, 'learning_rate': 0.005391704597620842, 'n_estimator': 826}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352190\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 167\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352482\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 169\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:30:57,816] Trial 13 finished with value: 0.05636697688737866 and parameters: {'num_leaves': 228, 'max_depth': 170, 'learning_rate': 0.06142578288681171, 'n_estimator': 737}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352526\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352319\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352320\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:30:59,705] Trial 14 finished with value: 0.06629025042520995 and parameters: {'num_leaves': 108, 'max_depth': 386, 'learning_rate': 0.061430967817849, 'n_estimator': 24}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352433\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352210\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:31:34,881] Trial 15 finished with value: 0.05656592407022979 and parameters: {'num_leaves': 154, 'max_depth': 168, 'learning_rate': 0.089909136344979, 'n_estimator': 1018}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352330\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 170\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352562\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352356\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 169\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352242\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:32:04,820] Trial 16 finished with value: 0.05614144780258172 and parameters: {'num_leaves': 215, 'max_depth': 445, 'learning_rate': 0.03609776689408274, 'n_estimator': 700}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352498\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352323\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352119\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 169\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:32:11,799] Trial 17 finished with value: 0.05630421259130458 and parameters: {'num_leaves': 9, 'max_depth': 161, 'learning_rate': 0.11103082888171911, 'n_estimator': 410}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 167\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352434\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352238\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352448\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 169\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352421\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:32:42,169] Trial 18 finished with value: 0.05789794498115438 and parameters: {'num_leaves': 200, 'max_depth': 446, 'learning_rate': 0.20902992469726667, 'n_estimator': 891}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352317\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352506\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352439\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:33:07,526] Trial 19 finished with value: 0.056108839285743395 and parameters: {'num_leaves': 148, 'max_depth': 438, 'learning_rate': 0.03971098104209781, 'n_estimator': 673}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352298\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 169\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352390\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352344\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352422\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:33:29,734] Trial 20 finished with value: 0.056466766018415916 and parameters: {'num_leaves': 97, 'max_depth': 227, 'learning_rate': 0.11751602564200081, 'n_estimator': 928}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352496\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352192\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352541\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352331\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:34:21,010] Trial 21 finished with value: 0.05612057245139106 and parameters: {'num_leaves': 115, 'max_depth': 485, 'learning_rate': 0.004886114403670498, 'n_estimator': 1004}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352265\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 168\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352234\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 170\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352428\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:34:53,113] Trial 22 finished with value: 0.05609085899674425 and parameters: {'num_leaves': 140, 'max_depth': 504, 'learning_rate': 0.03125904476417992, 'n_estimator': 791}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352372\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352379\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 169\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352352\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:35:46,872] Trial 23 finished with value: 0.056125919842728855 and parameters: {'num_leaves': 119, 'max_depth': 324, 'learning_rate': 0.005174472574243868, 'n_estimator': 953}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352273\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 166\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352545\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352336\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352301\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:36:08,733] Trial 24 finished with value: 0.05613682958107974 and parameters: {'num_leaves': 77, 'max_depth': 419, 'learning_rate': 0.05758043694758251, 'n_estimator': 767}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352483\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352236\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352286\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352405\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:36:34,163] Trial 25 finished with value: 0.05606166334395204 and parameters: {'num_leaves': 133, 'max_depth': 511, 'learning_rate': 0.027429808174928294, 'n_estimator': 651}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352331\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352535\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352186\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:36:49,543] Trial 26 finished with value: 0.05618228326459799 and parameters: {'num_leaves': 159, 'max_depth': 356, 'learning_rate': 0.08488763225882441, 'n_estimator': 407}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352296\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352556\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352071\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:37:12,410] Trial 27 finished with value: 0.056918476142230126 and parameters: {'num_leaves': 101, 'max_depth': 474, 'learning_rate': 0.18605545341671426, 'n_estimator': 937}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352213\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 170\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352336\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352616\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 168\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:38:04,237] Trial 28 finished with value: 0.056144361388596756 and parameters: {'num_leaves': 201, 'max_depth': 463, 'learning_rate': 0.02556490325085705, 'n_estimator': 1024}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352473\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352388\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352375\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 170\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352334\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 169\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:38:22,835] Trial 29 finished with value: 0.0561364323171434 and parameters: {'num_leaves': 47, 'max_depth': 424, 'learning_rate': 0.07638882488574578, 'n_estimator': 857}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 170\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352238\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352247\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 167\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352624\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:38:38,362] Trial 30 finished with value: 0.05625537281108077 and parameters: {'num_leaves': 85, 'max_depth': 380, 'learning_rate': 0.11902259295502632, 'n_estimator': 609}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352473\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352528\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352127\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 179\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:39:03,049] Trial 31 finished with value: 0.05604183252824883 and parameters: {'num_leaves': 131, 'max_depth': 410, 'learning_rate': 0.021841480687821706, 'n_estimator': 479}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352422\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352285\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:39:21,949] Trial 32 finished with value: 0.05608927575628201 and parameters: {'num_leaves': 125, 'max_depth': 406, 'learning_rate': 0.049443822697090044, 'n_estimator': 504}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 170\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352218\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352437\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352570\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:39:45,471] Trial 33 finished with value: 0.056040728538950445 and parameters: {'num_leaves': 143, 'max_depth': 335, 'learning_rate': 0.018086784162432527, 'n_estimator': 405}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352183\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352261\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:40:08,028] Trial 34 finished with value: 0.05604143553567757 and parameters: {'num_leaves': 172, 'max_depth': 282, 'learning_rate': 0.023632199562509504, 'n_estimator': 347}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 170\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352339\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352515\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352488\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352336\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:40:23,765] Trial 35 finished with value: 0.056121579230787665 and parameters: {'num_leaves': 168, 'max_depth': 264, 'learning_rate': 0.07526818637961666, 'n_estimator': 356}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352350\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352235\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352301\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:40:43,200] Trial 36 finished with value: 0.05605220113257572 and parameters: {'num_leaves': 174, 'max_depth': 350, 'learning_rate': 0.020926752000070742, 'n_estimator': 290}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352552\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352284\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352397\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:40:59,982] Trial 37 finished with value: 0.05631000018685722 and parameters: {'num_leaves': 189, 'max_depth': 283, 'learning_rate': 0.1010893584382897, 'n_estimator': 458}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352329\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 178\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352524\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:41:09,446] Trial 38 finished with value: 0.05604193437231023 and parameters: {'num_leaves': 143, 'max_depth': 217, 'learning_rate': 0.05427582161056233, 'n_estimator': 211}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352375\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 170\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352468\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 172\n",
      "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-21 19:41:36,933] Trial 39 finished with value: 0.056143098012558304 and parameters: {'num_leaves': 245, 'max_depth': 333, 'learning_rate': 0.04273995067570475, 'n_estimator': 544}. Best is trial 8 with value: 0.05603844107634207.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352469\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352359\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 179\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352200\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 174\n",
      "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.352342\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8784033f-af93-4ede-8c01-6a3a198023ac",
   "metadata": {},
   "source": [
    "#### Full train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
