{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a0c7da5-d8cb-4f67-9166-48b9f4f8b4e7",
   "metadata": {},
   "source": [
    "## In this notebook i'll try clustering then applying SGD (linear for high n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b7faaa-6e26-4e12-8204-0a14f1bfcb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/train_pp.csv')\n",
    "test_df = pd.read_csv('data/test_pp.csv')\n",
    "\n",
    "X = df.drop(['accident_risk', 'id'], axis=1)\n",
    "y = df['accident_risk']\n",
    "\n",
    "def submission_generator(trained_model):\n",
    "    test_df_preprocessed = test_df.drop('id', axis=1)\n",
    "    return pd.concat([test_df['id'], pd.Series(trained_model.predict(test_df_preprocessed))], axis=1).rename({0: 'accident_risk'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2950ff0-f047-490d-a12a-3f1ff638e6bc",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7560dd23-d259-4747-a6a0-1d7a930625a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f36d21-c409-4a48-ac9a-398220ae1375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== n_clusters = 8 ===\n"
     ]
    }
   ],
   "source": [
    "range_n_clusters = [2, 4, 6, 8, 10]\n",
    "range_n_clusters = [8]\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    print(f\"\\n=== n_clusters = {n_clusters} ===\")\n",
    "    fold_scores = []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_test = X.iloc[test_idx]\n",
    "        y_test = y.iloc[test_idx]\n",
    "\n",
    "        kmeans = KMeans(n_clusters=n_clusters)\n",
    "        cluster_labels_train = kmeans.fit_predict(X_train)\n",
    "        cluster_labels_test = kmeans.predict(X_test)\n",
    "\n",
    "        preds = np.zeros_like(y_test, dtype=float)\n",
    "\n",
    "        for c in range(n_clusters):\n",
    "            idx_train = np.where(cluster_labels_train == c)[0]\n",
    "            idx_test = np.where(cluster_labels_test == c)[0]\n",
    "\n",
    "            if len(idx_train) == 0 or len(idx_test) == 0:\n",
    "                continue \n",
    "\n",
    "            sgd = SGDRegressor(\n",
    "                penalty=None,\n",
    "                alpha = 4.223601774273774,\n",
    "                l1_ratio=0.8940821225850496,\n",
    "                max_iter=5_000\n",
    "            )\n",
    "            sgd.fit(X_train.iloc[idx_train], y_train.iloc[idx_train])\n",
    "            preds[idx_test] = sgd.predict(X_test.iloc[idx_test])\n",
    "\n",
    "        fold_score = root_mean_squared_error(y_test, preds)\n",
    "        print(fold_score)\n",
    "        fold_scores.append(fold_score)\n",
    "\n",
    "    print(f\"Mean CV root mean squared for {n_clusters} clusters: {np.mean(fold_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a808f9ee-9dea-40ae-be08-9d8588574680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3631d5-6f74-4c00-9fcd-83303c433d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== DBSCAN ====================\n",
      "\n",
      "--- DBSCAN (eps=0.3, min_samples=3) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold RMSE: 4966493344438.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold RMSE: 4950390732226.8760\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import (\n",
    "    KMeans, MiniBatchKMeans, AgglomerativeClustering,\n",
    "    SpectralClustering, DBSCAN\n",
    ")\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# Example ranges (you can modify)\n",
    "range_n_clusters = [2, 4, 6, 8, 10]\n",
    "range_n_clusters = [2]\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Define clustering methods\n",
    "clustering_methods = {\n",
    "    # \"KMeans\": KMeans,\n",
    "    # \"MiniBatchKMeans\": MiniBatchKMeans,\n",
    "    # \"GaussianMixture\": GaussianMixture,\n",
    "    # \"AgglomerativeClustering\": AgglomerativeClustering,\n",
    "    # \"SpectralClustering\": SpectralClustering,\n",
    "    \"DBSCAN\": DBSCAN\n",
    "}\n",
    "\n",
    "for method_name, ClusteringModel in clustering_methods.items():\n",
    "    print(f\"\\n{'='*20} {method_name} {'='*20}\")\n",
    "\n",
    "    # Handle DBSCAN separately (no n_clusters parameter)\n",
    "    if method_name == \"DBSCAN\":\n",
    "        eps_values = [0.3, 0.5, 0.7]\n",
    "        min_samples_values = [3, 5]\n",
    "\n",
    "        for eps in eps_values:\n",
    "            for min_samples in min_samples_values:\n",
    "                print(f\"\\n--- DBSCAN (eps={eps}, min_samples={min_samples}) ---\")\n",
    "                fold_scores = []\n",
    "\n",
    "                for train_idx, test_idx in kf.split(X):\n",
    "                    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "                    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "                    clusterer = ClusteringModel(eps=eps, min_samples=min_samples)\n",
    "                    cluster_labels_train = clusterer.fit_predict(X_train)\n",
    "\n",
    "                    # DBSCAN doesnâ€™t support .predict(), so re-fit on combined data\n",
    "                    clusterer_full = ClusteringModel(eps=eps, min_samples=min_samples)\n",
    "                    cluster_labels = clusterer_full.fit_predict(pd.concat([X_train, X_test]))\n",
    "                    cluster_labels_test = cluster_labels[len(X_train):]\n",
    "\n",
    "                    preds = np.zeros_like(y_test, dtype=float)\n",
    "                    unique_clusters = np.unique(cluster_labels_train[cluster_labels_train != -1])\n",
    "\n",
    "                    for c in unique_clusters:\n",
    "                        idx_train = np.where(cluster_labels_train == c)[0]\n",
    "                        idx_test = np.where(cluster_labels_test == c)[0]\n",
    "\n",
    "                        if len(idx_train) == 0 or len(idx_test) == 0:\n",
    "                            continue\n",
    "\n",
    "                        sgd = SGDRegressor(\n",
    "                            penalty=None,\n",
    "                            alpha=4.223601774273774,\n",
    "                            l1_ratio=0.8940821225850496,\n",
    "                            max_iter=5000\n",
    "                        )\n",
    "                        sgd.fit(X_train.iloc[idx_train], y_train.iloc[idx_train])\n",
    "                        preds[idx_test] = sgd.predict(X_test.iloc[idx_test])\n",
    "\n",
    "                    fold_score = root_mean_squared_error(y_test, preds)\n",
    "                    print(f\"Fold RMSE: {fold_score:.4f}\")\n",
    "                    fold_scores.append(fold_score)\n",
    "\n",
    "                print(f\"Mean CV RMSE (eps={eps}, min_samples={min_samples}): {np.mean(fold_scores):.4f}\")\n",
    "\n",
    "    # Handle normal clustering methods\n",
    "    else:\n",
    "        for n_clusters in range_n_clusters:\n",
    "            print(f\"\\n--- n_clusters = {n_clusters} ---\")\n",
    "            fold_scores = []\n",
    "\n",
    "            for train_idx, test_idx in kf.split(X):\n",
    "                X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "                y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "                # Instantiate clustering model\n",
    "                if method_name == \"GaussianMixture\":\n",
    "                    clusterer = ClusteringModel(n_components=n_clusters, random_state=42)\n",
    "                    cluster_labels_train = clusterer.fit_predict(X_train)\n",
    "                    cluster_labels_test = clusterer.predict(X_test)\n",
    "                elif method_name in [\"AgglomerativeClustering\", \"SpectralClustering\"]:\n",
    "                    clusterer = ClusteringModel(n_clusters=n_clusters)\n",
    "                    cluster_labels = clusterer.fit_predict(pd.concat([X_train, X_test]))\n",
    "                    cluster_labels_train = cluster_labels[:len(X_train)]\n",
    "                    cluster_labels_test = cluster_labels[len(X_train):]\n",
    "                else:\n",
    "                    clusterer = ClusteringModel(n_clusters=n_clusters, random_state=42)\n",
    "                    cluster_labels_train = clusterer.fit_predict(X_train)\n",
    "                    cluster_labels_test = clusterer.predict(X_test)\n",
    "\n",
    "                preds = np.zeros_like(y_test, dtype=float)\n",
    "\n",
    "                for c in range(n_clusters):\n",
    "                    idx_train = np.where(cluster_labels_train == c)[0]\n",
    "                    idx_test = np.where(cluster_labels_test == c)[0]\n",
    "\n",
    "                    if len(idx_train) == 0 or len(idx_test) == 0:\n",
    "                        continue\n",
    "\n",
    "                    sgd = SGDRegressor(\n",
    "                        penalty=None,\n",
    "                        alpha=4.223601774273774,\n",
    "                        l1_ratio=0.8940821225850496,\n",
    "                        max_iter=5000\n",
    "                    )\n",
    "                    sgd.fit(X_train.iloc[idx_train], y_train.iloc[idx_train])\n",
    "                    preds[idx_test] = sgd.predict(X_test.iloc[idx_test])\n",
    "\n",
    "                fold_score = root_mean_squared_error(y_test, preds)\n",
    "                print(f\"Fold RMSE: {fold_score:.4f}\")\n",
    "                fold_scores.append(fold_score)\n",
    "\n",
    "            print(f\"Mean CV RMSE for {n_clusters} clusters: {np.mean(fold_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca93d51-2db2-4d77-a8b5-752300c580bf",
   "metadata": {},
   "source": [
    "==================== KMeans ====================\n",
    "\n",
    "--- n_clusters = 2 ---\n",
    "Fold RMSE: 0.3478\n",
    "Fold RMSE: 0.4287\n",
    "Fold RMSE: 0.4337\n",
    "Fold RMSE: 0.4720\n",
    "Fold RMSE: 0.4335\n",
    "Mean CV RMSE for 2 clusters: 0.4232\n",
    "\n",
    "==================== MiniBatchKMeans ====================\n",
    "\n",
    "--- n_clusters = 2 ---\n",
    "Fold RMSE: 0.4418\n",
    "Fold RMSE: 0.4515\n",
    "Fold RMSE: 0.4592\n",
    "Fold RMSE: 0.3536\n",
    "Fold RMSE: 0.3318\n",
    "Mean CV RMSE for 2 clusters: 0.4076\n",
    "\n",
    "==================== GaussianMixture ====================\n",
    "\n",
    "--- n_clusters = 2 ---\n",
    "Fold RMSE: 0.1868\n",
    "Fold RMSE: 0.2020\n",
    "Fold RMSE: 0.1998\n",
    "Fold RMSE: 0.1889\n",
    "Fold RMSE: 0.2110\n",
    "Mean CV RMSE for 2 clusters: 0.1977"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
